{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "957cc1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7300e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f8a83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, metrics, linear_model, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from imblearn.over_sampling import BorderlineSMOTE, SMOTE, ADASYN, SMOTENC, RandomOverSampler\n",
    "from imblearn.under_sampling import (RandomUnderSampler, \n",
    "                                    NearMiss, \n",
    "                                    InstanceHardnessThreshold,\n",
    "                                    CondensedNearestNeighbour,\n",
    "                                    EditedNearestNeighbours,\n",
    "                                    RepeatedEditedNearestNeighbours,\n",
    "                                    AllKNN,\n",
    "                                    NeighbourhoodCleaningRule,\n",
    "                                    OneSidedSelection,\n",
    "                                    TomekLinks)\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d3945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8861fcb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>unclean_tweets</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>first100charactersoftweets</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>clean_tweets_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>non_punctuated_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1477985792605757447</td>\n",
       "      <td>@OctoSquid_503 I put about 50-60 hours into th...</td>\n",
       "      <td>put hours game last year still holds well blas...</td>\n",
       "      <td>put hours game last year still holds well blas...</td>\n",
       "      <td>-0.047619</td>\n",
       "      <td>0.545238</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>put hours game last year still holds well blas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1477984041248989187</td>\n",
       "      <td>A story about why 2021 was great and not terri...</td>\n",
       "      <td>story great terrible</td>\n",
       "      <td>story great terrible</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.1803</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>story great terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1477983892665688069</td>\n",
       "      <td>The jaedo event I bought tickets for in the 2n...</td>\n",
       "      <td>jaedo event bought tickets nd quarter finally ...</td>\n",
       "      <td>jaedo event bought tickets nd quarter finally ...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.214</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>114</td>\n",
       "      <td>18</td>\n",
       "      <td>jaedo event bought tickets nd quarter finally ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1477981564323569664</td>\n",
       "      <td>this year is going to be super dynamic for me ...</td>\n",
       "      <td>year going super dynamic bc im graduating uni ...</td>\n",
       "      <td>year going super dynamic bc im graduating uni ...</td>\n",
       "      <td>0.130556</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>year going super dynamic bc im graduating uni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1477981357535944707</td>\n",
       "      <td>2021 literally such a tough year ðŸ˜­ none of the...</td>\n",
       "      <td>literally tough year none plan going right pre...</td>\n",
       "      <td>literally tough year none plan going right pre...</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>0.684127</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>112</td>\n",
       "      <td>20</td>\n",
       "      <td>literally tough year none plan going right pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                     unclean_tweets  \\\n",
       "0  1477985792605757447  @OctoSquid_503 I put about 50-60 hours into th...   \n",
       "1  1477984041248989187  A story about why 2021 was great and not terri...   \n",
       "2  1477983892665688069  The jaedo event I bought tickets for in the 2n...   \n",
       "3  1477981564323569664  this year is going to be super dynamic for me ...   \n",
       "4  1477981357535944707  2021 literally such a tough year ðŸ˜­ none of the...   \n",
       "\n",
       "                                        clean_tweets  \\\n",
       "0  put hours game last year still holds well blas...   \n",
       "1                               story great terrible   \n",
       "2  jaedo event bought tickets nd quarter finally ...   \n",
       "3  year going super dynamic bc im graduating uni ...   \n",
       "4  literally tough year none plan going right pre...   \n",
       "\n",
       "                          first100charactersoftweets  polarity  subjectivity  \\\n",
       "0  put hours game last year still holds well blas... -0.047619      0.545238   \n",
       "1                               story great terrible -0.100000      0.875000   \n",
       "2  jaedo event bought tickets nd quarter finally ... -0.333333      1.000000   \n",
       "3  year going super dynamic bc im graduating uni ...  0.130556      0.477778   \n",
       "4  literally tough year none plan going right pre...  0.005423      0.684127   \n",
       "\n",
       "  sentiment    neg    neu    pos  compound  clean_tweets_length  word_count  \\\n",
       "0  positive  0.000  0.815  0.185    0.6124                  122          20   \n",
       "1  positive  0.165  0.588  0.248    0.1803                   20           3   \n",
       "2  negative  0.230  0.556  0.214   -0.0516                  114          18   \n",
       "3  positive  0.000  0.772  0.228    0.6808                  178          31   \n",
       "4  positive  0.000  0.843  0.157    0.3818                  112          20   \n",
       "\n",
       "                               non_punctuated_tweets  \n",
       "0  put hours game last year still holds well blas...  \n",
       "1                               story great terrible  \n",
       "2  jaedo event bought tickets nd quarter finally ...  \n",
       "3  year going super dynamic bc im graduating uni ...  \n",
       "4  literally tough year none plan going right pre...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d2c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=data[['non_punctuated_tweets','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9956c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'put hours game last year still holds well blast playing definitely one highlights great still active sad day servers empty'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.non_punctuated_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda9d037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_punctuated_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>put hours game last year still holds well blas...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story great terrible</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jaedo event bought tickets nd quarter finally ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year going super dynamic bc im graduating uni ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literally tough year none plan going right pre...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>really rough one mental health truly feel many...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17770</th>\n",
       "      <td>happy new year everyone except boy dated coupl...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17771</th>\n",
       "      <td>crazy bought car moved shot porn butt plug bum...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17772</th>\n",
       "      <td>think descent art year despite able use tablet...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17773</th>\n",
       "      <td>hi active moment wanted say happy new year acc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17774 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   non_punctuated_tweets sentiment\n",
       "0      put hours game last year still holds well blas...  positive\n",
       "1                                   story great terrible  positive\n",
       "2      jaedo event bought tickets nd quarter finally ...  negative\n",
       "3      year going super dynamic bc im graduating uni ...  positive\n",
       "4      literally tough year none plan going right pre...  positive\n",
       "...                                                  ...       ...\n",
       "17769  really rough one mental health truly feel many...  positive\n",
       "17770  happy new year everyone except boy dated coupl...  positive\n",
       "17771  crazy bought car moved shot porn butt plug bum...  negative\n",
       "17772  think descent art year despite able use tablet...   neutral\n",
       "17773  hi active moment wanted say happy new year acc...  positive\n",
       "\n",
       "[17774 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b21227f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "Data['sentiment'] = Data['sentiment'].replace('positive',1)\n",
    "Data['sentiment'] = Data['sentiment'].replace('negative',-1)\n",
    "Data['sentiment'] = Data['sentiment'].replace('neutral',0)\n",
    "\n",
    "### code for encoding the meaning of positive negative and  neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5149323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2       -1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "17769    1\n",
       "17770    1\n",
       "17771   -1\n",
       "17772    0\n",
       "17773    1\n",
       "Name: sentiment, Length: 17774, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c1c7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d11c83fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    12622\n",
       "-1     3823\n",
       " 0     1329\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5077850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        put hours game last year still holds well blas...\n",
       "1                                     story great terrible\n",
       "2        jaedo event bought tickets nd quarter finally ...\n",
       "3        year going super dynamic bc im graduating uni ...\n",
       "4        literally tough year none plan going right pre...\n",
       "                               ...                        \n",
       "17769    really rough one mental health truly feel many...\n",
       "17770    happy new year everyone except boy dated coupl...\n",
       "17771    crazy bought car moved shot porn butt plug bum...\n",
       "17772    think descent art year despite able use tablet...\n",
       "17773    hi active moment wanted say happy new year acc...\n",
       "Name: non_punctuated_tweets, Length: 17774, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Data['non_punctuated_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a47956fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference variable for Class TweetTokenizer\n",
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de948835",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3060/3733908120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#from nltk.tokenize import RegexpTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#tokenizer = RegexpTokenizer(r'w+')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tokenized_tweets'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'non_punctuated_tweets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#Data['tokenized_tweets'].head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m                     \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m                 )\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\nltk\\tokenize\\casual.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \"\"\"\n\u001b[0;32m    343\u001b[0m         \u001b[1;31m# Fix HTML character entities:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_replace_html_entities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[1;31m# Remove username handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip_handles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\nltk\\tokenize\\casual.py\u001b[0m in \u001b[0;36m_replace_html_entities\u001b[1;34m(text, keep, remove_illegal, encoding)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mremove_illegal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mENT_RE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_entity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_str_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer = RegexpTokenizer(r'w+')\n",
    "Data['tokenized_tweets'] = Data['non_punctuated_tweets'].apply(tt.tokenize)\n",
    "#Data['tokenized_tweets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf845f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non_punctuated_tweets</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>put hours game last year still holds well blas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story great terrible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jaedo event bought tickets nd quarter finally ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year going super dynamic bc im graduating uni ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literally tough year none plan going right pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>really rough one mental health truly feel many...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17770</th>\n",
       "      <td>happy new year everyone except boy dated coupl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17771</th>\n",
       "      <td>crazy bought car moved shot porn butt plug bum...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17772</th>\n",
       "      <td>think descent art year despite able use tablet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17773</th>\n",
       "      <td>hi active moment wanted say happy new year acc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17774 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   non_punctuated_tweets  sentiment\n",
       "0      put hours game last year still holds well blas...          1\n",
       "1                                   story great terrible          1\n",
       "2      jaedo event bought tickets nd quarter finally ...         -1\n",
       "3      year going super dynamic bc im graduating uni ...          1\n",
       "4      literally tough year none plan going right pre...          1\n",
       "...                                                  ...        ...\n",
       "17769  really rough one mental health truly feel many...          1\n",
       "17770  happy new year everyone except boy dated coupl...          1\n",
       "17771  crazy bought car moved shot porn butt plug bum...         -1\n",
       "17772  think descent art year despite able use tablet...          0\n",
       "17773  hi active moment wanted say happy new year acc...          1\n",
       "\n",
       "[17774 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7df40b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [put, hour, game, last, year, still, hold, wel...\n",
       "1                              [stori, great, terribl]\n",
       "2    [jaedo, event, bought, ticket, nd, quarter, fi...\n",
       "3    [year, go, super, dynam, bc, im, graduat, uni,...\n",
       "4    [liter, tough, year, none, plan, go, right, pr...\n",
       "Name: stemmed_tweets, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return text\n",
    "Data['stemmed_tweets']= Data['tokenized_tweets'].apply(lambda x: stemming_on_text(x))\n",
    "Data['stemmed_tweets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3604acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Data.non_punctuated_tweets\n",
    "y=Data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3aa7734",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "767315c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb9dfb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state =26105111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5a46fa",
   "metadata": {},
   "source": [
    "# converting tweets to vectors using TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "622b5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(X)\n",
    "X_train_tfidf =  tfidf_vect.transform(X_train)\n",
    "X_test_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1ac50",
   "metadata": {},
   "source": [
    "# Modelling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9a3d7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the f1 Score\n",
    "def train_model(name_of_classifier,classifier, feature_vector_train, label, feature_vector_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_test)\n",
    "    f1_micro = metrics.f1_score(y_test,predictions,average = 'micro')\n",
    "    f1_macro = metrics.f1_score(y_test,predictions,average = 'macro')\n",
    "    f1_weighted = metrics.f1_score(y_test,predictions,average = 'weighted')\n",
    "    accuracy = accuracy_score(y_test,predictions)\n",
    "    return pd.DataFrame({'model':[name_of_classifier],'f1_micro':[f1_micro],'f1_macro':[f1_macro],'f1_weighted':[f1_weighted],'accuracy':[accuracy]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f39d9",
   "metadata": {},
   "source": [
    "# without resampling the imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9cff2db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistc_regression</td>\n",
       "      <td>0.715049</td>\n",
       "      <td>0.367108</td>\n",
       "      <td>0.640890</td>\n",
       "      <td>0.715049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.691139</td>\n",
       "      <td>0.404903</td>\n",
       "      <td>0.647170</td>\n",
       "      <td>0.691139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.688608</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>0.627255</td>\n",
       "      <td>0.688608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.712799</td>\n",
       "      <td>0.280867</td>\n",
       "      <td>0.596135</td>\n",
       "      <td>0.712799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  f1_micro  f1_macro  f1_weighted  accuracy\n",
       "0  logistc_regression  0.715049  0.367108     0.640890  0.715049\n",
       "1                 SVM  0.691139  0.404903     0.647170  0.691139\n",
       "2         BernoulliNB  0.688608  0.351600     0.627255  0.688608\n",
       "3       MultinomialNB  0.712799  0.280867     0.596135  0.712799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),X_train_tfidf, y_train, X_test_tfidf)\n",
    "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
    "second = train_model('SVM',LinearSVC(),X_train_tfidf, y_train, X_test_tfidf)\n",
    "third =  train_model('BernoulliNB',BernoulliNB(),X_train_tfidf, y_train, X_test_tfidf)\n",
    "fourth =  train_model('MultinomialNB',MultinomialNB(),X_train_tfidf, y_train, X_test_tfidf)\n",
    "\n",
    "frames = [first,second,third,fourth]\n",
    "combined = pd.concat(frames)\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41495ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#model=BernoulliNB()\n",
    "#model.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180cde7",
   "metadata": {},
   "source": [
    "# Random OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6e9c3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Over Sampling\n",
    "ros = RandomOverSampler(random_state=777)\n",
    "ros_X_train_tfidf, ros_y_train = ros.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "961b1aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistc_regression</td>\n",
       "      <td>0.602813</td>\n",
       "      <td>0.440973</td>\n",
       "      <td>0.620707</td>\n",
       "      <td>0.602813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.604782</td>\n",
       "      <td>0.417512</td>\n",
       "      <td>0.617462</td>\n",
       "      <td>0.604782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.562025</td>\n",
       "      <td>0.425878</td>\n",
       "      <td>0.595448</td>\n",
       "      <td>0.562025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.600844</td>\n",
       "      <td>0.449748</td>\n",
       "      <td>0.621284</td>\n",
       "      <td>0.600844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  f1_micro  f1_macro  f1_weighted  accuracy\n",
       "0  logistc_regression  0.602813  0.440973     0.620707  0.602813\n",
       "1                 SVM  0.604782  0.417512     0.617462  0.604782\n",
       "2         BernoulliNB  0.562025  0.425878     0.595448  0.562025\n",
       "3       MultinomialNB  0.600844  0.449748     0.621284  0.600844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
    "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
    "second = train_model('SVM',LinearSVC(),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
    "third =  train_model('BernoulliNB',BernoulliNB(),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
    "fourth =  train_model('MultinomialNB',MultinomialNB(),ros_X_train_tfidf, ros_y_train, X_test_tfidf)\n",
    "\n",
    "frames = [first,second,third,fourth]\n",
    "combined = pd.concat(frames)\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c0560",
   "metadata": {},
   "source": [
    "# SMOTE Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ff1b641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=777)\n",
    "sm_X_train_tfidf, sm_y_train = sm.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "668402df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistc_regression</td>\n",
       "      <td>0.602250</td>\n",
       "      <td>0.435314</td>\n",
       "      <td>0.618899</td>\n",
       "      <td>0.602250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.593812</td>\n",
       "      <td>0.412383</td>\n",
       "      <td>0.608538</td>\n",
       "      <td>0.593812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.645288</td>\n",
       "      <td>0.410574</td>\n",
       "      <td>0.631968</td>\n",
       "      <td>0.645288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.579747</td>\n",
       "      <td>0.437375</td>\n",
       "      <td>0.605700</td>\n",
       "      <td>0.579747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  f1_micro  f1_macro  f1_weighted  accuracy\n",
       "0  logistc_regression  0.602250  0.435314     0.618899  0.602250\n",
       "1                 SVM  0.593812  0.412383     0.608538  0.593812\n",
       "2         BernoulliNB  0.645288  0.410574     0.631968  0.645288\n",
       "3       MultinomialNB  0.579747  0.437375     0.605700  0.579747"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
    "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
    "second = train_model('SVM',LinearSVC(),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
    "third =  train_model('BernoulliNB',BernoulliNB(),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
    "fourth =  train_model('MultinomialNB',MultinomialNB(),sm_X_train_tfidf, sm_y_train, X_test_tfidf)\n",
    "\n",
    "frames = [first,second,third,fourth]\n",
    "combined = pd.concat(frames)\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3708a6b5",
   "metadata": {},
   "source": [
    "# ADASYN: Adaptive synthetic sampling (Over-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b747d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADASYN\n",
    "ad = ADASYN(random_state=777)\n",
    "ad_xtrain_tfidf, ad_train_y = ad.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4cba4cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistc_regression</td>\n",
       "      <td>0.600844</td>\n",
       "      <td>0.438161</td>\n",
       "      <td>0.618236</td>\n",
       "      <td>0.600844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.588748</td>\n",
       "      <td>0.410657</td>\n",
       "      <td>0.605510</td>\n",
       "      <td>0.588748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.643601</td>\n",
       "      <td>0.406235</td>\n",
       "      <td>0.629260</td>\n",
       "      <td>0.643601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.587342</td>\n",
       "      <td>0.436590</td>\n",
       "      <td>0.611706</td>\n",
       "      <td>0.587342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  f1_micro  f1_macro  f1_weighted  accuracy\n",
       "0  logistc_regression  0.600844  0.438161     0.618236  0.600844\n",
       "1                 SVM  0.588748  0.410657     0.605510  0.588748\n",
       "2         BernoulliNB  0.643601  0.406235     0.629260  0.643601\n",
       "3       MultinomialNB  0.587342  0.436590     0.611706  0.587342"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
    "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
    "second = train_model('SVM',LinearSVC(),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
    "third =  train_model('BernoulliNB',BernoulliNB(),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
    "fourth =  train_model('MultinomialNB',MultinomialNB(),ad_xtrain_tfidf, ad_train_y, X_test_tfidf)\n",
    "\n",
    "frames = [first,second,third,fourth]\n",
    "combined = pd.concat(frames)\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704ae72",
   "metadata": {},
   "source": [
    "# BorderLine SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b587717",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm = BorderlineSMOTE()\n",
    "bsm_xtrain_tfidf, bsm_train_y = bsm.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ac0d856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistc_regression</td>\n",
       "      <td>0.612377</td>\n",
       "      <td>0.439430</td>\n",
       "      <td>0.625027</td>\n",
       "      <td>0.612377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.600563</td>\n",
       "      <td>0.414806</td>\n",
       "      <td>0.612941</td>\n",
       "      <td>0.600563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.649789</td>\n",
       "      <td>0.415879</td>\n",
       "      <td>0.634865</td>\n",
       "      <td>0.649789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.595781</td>\n",
       "      <td>0.450686</td>\n",
       "      <td>0.618201</td>\n",
       "      <td>0.595781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  f1_micro  f1_macro  f1_weighted  accuracy\n",
       "0  logistc_regression  0.612377  0.439430     0.625027  0.612377\n",
       "1                 SVM  0.600563  0.414806     0.612941  0.600563\n",
       "2         BernoulliNB  0.649789  0.415879     0.634865  0.649789\n",
       "3       MultinomialNB  0.595781  0.450686     0.618201  0.595781"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
    "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
    "second = train_model('SVM',LinearSVC(),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
    "third =  train_model('BernoulliNB',BernoulliNB(),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
    "fourth =  train_model('MultinomialNB',MultinomialNB(),bsm_xtrain_tfidf, bsm_train_y, X_test_tfidf)\n",
    "\n",
    "frames = [first,second,third,fourth]\n",
    "combined = pd.concat(frames)\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d96a0a",
   "metadata": {},
   "source": [
    "# Random Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ce747af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
    "rus_xtrain_tfidf, rus_train_y = rus.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "88f73ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistc_regression</td>\n",
       "      <td>0.450352</td>\n",
       "      <td>0.377926</td>\n",
       "      <td>0.505146</td>\n",
       "      <td>0.450352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.360309</td>\n",
       "      <td>0.488528</td>\n",
       "      <td>0.432911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.409283</td>\n",
       "      <td>0.340443</td>\n",
       "      <td>0.472285</td>\n",
       "      <td>0.409283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.556399</td>\n",
       "      <td>0.422520</td>\n",
       "      <td>0.586896</td>\n",
       "      <td>0.556399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  f1_micro  f1_macro  f1_weighted  accuracy\n",
       "0  logistc_regression  0.450352  0.377926     0.505146  0.450352\n",
       "1                 SVM  0.432911  0.360309     0.488528  0.432911\n",
       "2         BernoulliNB  0.409283  0.340443     0.472285  0.409283\n",
       "3       MultinomialNB  0.556399  0.422520     0.586896  0.556399"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),rus_xtrain_tfidf, rus_train_y ,X_test_tfidf)\n",
    "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
    "second = train_model('SVM',LinearSVC(),rus_xtrain_tfidf, rus_train_y, X_test_tfidf)\n",
    "third =  train_model('BernoulliNB',BernoulliNB(),rus_xtrain_tfidf, rus_train_y, X_test_tfidf)\n",
    "fourth =  train_model('MultinomialNB',MultinomialNB(),rus_xtrain_tfidf, rus_train_y, X_test_tfidf)\n",
    "\n",
    "frames = [first,second,third,fourth]\n",
    "combined = pd.concat(frames)\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147d363",
   "metadata": {},
   "source": [
    "# Tomek Link Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a62ab7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TomekLinks()\n",
    "tl_xtrain_tfidf, tl_train_y = tl.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0d5f64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olazaah\\Anaconda3\\envs\\tensorlow1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistc_regression</td>\n",
       "      <td>0.719550</td>\n",
       "      <td>0.371198</td>\n",
       "      <td>0.643053</td>\n",
       "      <td>0.719550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.693671</td>\n",
       "      <td>0.403787</td>\n",
       "      <td>0.648962</td>\n",
       "      <td>0.693671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.691702</td>\n",
       "      <td>0.346016</td>\n",
       "      <td>0.625138</td>\n",
       "      <td>0.691702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.713361</td>\n",
       "      <td>0.279274</td>\n",
       "      <td>0.595293</td>\n",
       "      <td>0.713361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  f1_micro  f1_macro  f1_weighted  accuracy\n",
       "0  logistc_regression  0.719550  0.371198     0.643053  0.719550\n",
       "1                 SVM  0.693671  0.403787     0.648962  0.693671\n",
       "2         BernoulliNB  0.691702  0.346016     0.625138  0.691702\n",
       "3       MultinomialNB  0.713361  0.279274     0.595293  0.713361"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first = train_model('logistc_regression',LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial'),tl_xtrain_tfidf, tl_train_y ,X_test_tfidf)\n",
    "#print (\"LR Baseline, WordLevel TFIDF: \", accuracyORIGINAL)\n",
    "second = train_model('SVM',LinearSVC(),tl_xtrain_tfidf, tl_train_y , X_test_tfidf)\n",
    "third =  train_model('BernoulliNB',BernoulliNB(),tl_xtrain_tfidf, tl_train_y, X_test_tfidf)\n",
    "fourth =  train_model('MultinomialNB',MultinomialNB(),tl_xtrain_tfidf, tl_train_y , X_test_tfidf)\n",
    "\n",
    "frames = [first,second,third,fourth]\n",
    "combined = pd.concat(frames)\n",
    "combined.reset_index(drop=True, inplace=True)\n",
    "display(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded90880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
